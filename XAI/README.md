
# Explainable Machine Learning
This is a list of papers and codes about explainable machine learning.

### Keywords Convention

![](https://img.shields.io/badge/Self_Explaining-blue) Towards self-explaining methods or post-hoc explanations.

![](https://img.shields.io/badge/Analysis-green) The main explored property of explanations methods in the work.

## Table of Contents
- [Survey/Tutorial](#survey-paper)
- [Foundamental Explainable ML](#foundamental-XAI)
- [Explainable Methods in CV](#XAI-CV)
- [Explainable Methods in NLP](#XAI-NLP)
- [Explainable Methods in Recommendation](#XAI-Rec)
- [Other Explainable Methods](#XAI-Other)
- [Explainable Methods for OOD or Debias](#XAI-OOD)
- [Categorization](#catg)

<!--- * Title, in *NeurIPS* 2019. [\[paper\]]() [\[code\]]() ---> 

## Survey/Tutorial
* On Explainable AI: From Theory to Motivation, Industrial Applications and Coding Practices, AAAI 2021. [\[Link\]](https://xaitutorial2021.github.io/)

## Foundamental Explainable ML
* Towards A Rigorous Science of Interpretable Machine Learning. 2018. [\[Link\]](https://arxiv.org/abs/1702.08608)

## Explainable Methods in CV


## Explainable Methods in NLP


## Explainable Methods in GNN
* Towards Self-Explainable Graph Neural Network, *CIKM* 2021. [\[paper\]](https://dl.acm.org/doi/pdf/10.1145/3459637.3482306?casa_token=QCWCRWnwCR0AAAAA:JAdj8PtPoxVUW4annpOC-o0hg-nndjM3jZaJNMPTy2VWR9eSjUBczrBIDwF7Rb5pGrRm0dvNtOAfYQ) ![](https://img.shields.io/badge/Self_Explaining-blue)


## Explainable Methods in Recommendation


## Other Explainable Methods


## Explainable Methods for OOD or Debias

## Categorization
### Saliency Maps
* Axiomatic attribution for deep networks. *ICML* 2017. [\[paper\]](https://arxiv.org/abs/1703.01365)
* A unified approach to interpreting model predictions, *NeurIPS* 2017. [\[paper\]](https://arxiv.org/abs/1705.07874)
* Smooth-Grad: Removing noise by adding noise, *ICML VDL* 2017. [\[paper\]](https://arxiv.org/abs/1706.03825)

### Examples
* Interpretability for Language Learners Using Example-Based Grammatical Error Correction, *ACL* 2022. [\[paper\]](https://arxiv.org/pdf/2203.07085.pdf)
* Interpreting black box predictions using Fisher kernels, 2019. [\[paper\]](https://arxiv.org/abs/1810.10118)
* Representer Point Selection for Explaining Deep Neural Networks, *NeurIPS* 2018.[\[paper\]](https://arxiv.org/abs/1811.09720)
* Learning latent subspaces in variational autoencoders, *NeurIPS* 2018. [\[paper\]](https://proceedings.neurips.cc/paper/2018/file/73e5080f0f3804cb9cf470a8ce895dac-Paper.pdf)
* The Bayesian Case Model: A Generative Approach for Case-Based Reasoning and Prototype Classification, *NeurIPS* 2014. [\[paper\]](https://arxiv.org/abs/1503.01161)

### Concepts
*  Interpretability beyond feature attribution:  Quantitative testing with concept activationvectors (TCAV), *ICML* 2018. [\[paper\]](https://arxiv.org/abs/1711.11279)

### Shortcoming
* Learning to Deceive with Attention-Based Explanations, *ACL* 2019. [\[paper\]](https://arxiv.org/abs/1909.07913)
* Is attention interpretable? *ACL* 2019. [\[paper\]](https://arxiv.org/abs/1906.03731)
* Attention is not Explanation, *NAACL* 2019. [\[paper\]](https://arxiv.org/abs/1902.10186)
* Sanity checks for saliency maps, *NeurIPS* 2018. [\[paper\]](https://arxiv.org/abs/1810.03292)

### GAN
* Explanation by Progressive Exaggeration, *ICLR* 2020. [\[paper\]](https://arxiv.org/abs/1911.00483)
* Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations, *ICML* 2019. [\[paper\]](https://arxiv.org/abs/1811.12359)
* Info-GAN: Interpretable representation learning by information maximizing generative adversarialnets, *NeurIPS* 2018. [\[paper\]](https://arxiv.org/abs/1606.03657)
* ExplainGAN: Model Explanation via Decision Boundary Crossing Transformations, *ECCV* 2018. [\[paper\]](https://openaccess.thecvf.com/content_ECCV_2018/papers/Nathan_Silberman_ExplainGAN_Model_Explanation_ECCV_2018_paper.pdf)
* Disentangling by factorising, *ICML* 2018. [\[paper\]](https://arxiv.org/abs/1802.05983)
* beta-VAE: Learning basic visual con-cepts with a constrained variational framework, *ICLR* 2017. [\[paper\]](https://openreview.net/forum?id=Sy2fzU9gl)
* Deep Convolutional Inverse Graphics Network, *NeurIPS* 2015. [\[paper\]](https://arxiv.org/abs/1503.03167)


