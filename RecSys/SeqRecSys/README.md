
### Main
* Sequential Recommendation via Stochastic Self-Attention, in *WWW* 2022. [\[paper\]](https://dl.acm.org/doi/pdf/10.1145/3485447.3512077). [\[code\]](https://github.com/zfan20/STOSA) :thumbsup: 
    <details>
    <summary>Summary</summary>
    <strong>Motivation</strong>.  
    <strong>Solution</strong>. 
    <strong>Datasets</strong>.  
    <strong>Baselines</strong>. 
    <strong>Future</strong>. 
    <strong>Ins</strong>.
    </details>

### Contrastive Learning
* Intent Contrastive Learning for Sequential Recommendation, in *WWW* 2022. [\[paper\]](https://dl.acm.org/doi/pdf/10.1145/3485447.3512092). :thumbsup: 
    <details>
    <summary>Summary</summary>
    <strong>Motivation</strong>.  
    <strong>Solution</strong>. 
    <strong>Datasets</strong>.  
    <strong>Baselines</strong>. 
    <strong>Future</strong>. 
    <strong>Ins</strong>.
    </details>
    
### Debias
* Unbiased Sequential Recommendation with Latent Confounders, in *WWW* 2022. [\[paper\]](https://dl.acm.org/doi/pdf/10.1145/3485447.3512090). [\[code\]](https://github.com/salesforce/ICLRec) :thumbsup: 
    <details>
    <summary>Summary</summary>
    <strong>Motivation</strong>.  
    <strong>Solution</strong>. 
    <strong>Datasets</strong>.  
    <strong>Baselines</strong>. 
    <strong>Future</strong>. 
    <strong>Ins</strong>.
    </details>

### Sets2sets
* Element-guided Temporal Graph Representation Learning for Temporal Sets Prediction, in *WWW* 2022. [\[paper\]](https://dl.acm.org/doi/pdf/10.1145/3485447.3512064). [\[code\]](https://github.com/yule-BUAA/ETGNN) :thumbsup: 
    <details>
    <summary>Summary</summary>
    <strong>Motivation</strong>. Recent studies on temporal sets prediction follow the same pipeline that only learns from each userâ€™s own sequence, which fails to discover the collaborative signals among the sequences of **different users**. <strong>Solution</strong>. Element-guided larger graph. <strong>Datasets</strong>. DC, TaoBao, JD, and TMS.   <strong>Baselines</strong>. DNNTSP.
    <strong>Future</strong>. (1) Example-based interpretability? (2) Disentangling. (3) How to revise BasketTR based on this method. (4) DuoRec?
    <strong>Ins</strong>. Their model.
    </details>

### NAS
* Towards Automatic Discovering of Deep Hybrid Network Architecture for Sequential Recommendation, in *WWW* 2022. [\[paper\]](https://dl.acm.org/doi/pdf/10.1145/3485447.3512066)
